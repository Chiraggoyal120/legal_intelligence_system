# -*- coding: utf-8 -*-
"""legal_intelligence_system.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10VT3gfDvT7JWzE98ZGg0bR5YZhU7UN1k
"""

# Single command to install all required libraries:
!pip install sentence-transformers faiss-cpu gradio openai requests beautifulsoup4 pandas numpy python-dotenv transformers lxml pydantic

import os
os.environ['OPENROUTER_API_KEY'] = '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'

# Legal Intelligence Agentic System
  # Hannoworks Internship Assignment Implementation

  import os
  import json
  import requests
  import gradio as gr
  import numpy as np
  import pandas as pd
  from typing import List, Dict, Any, Tuple
  from dataclasses import dataclass
  from datetime import datetime
  import logging
  import re
  from bs4 import BeautifulSoup
  import pickle
  from sentence_transformers import SentenceTransformer
  import faiss
  from openai import OpenAI
  import asyncio
  from concurrent.futures import ThreadPoolExecutor

  # Configure logging
  logging.basicConfig(level=logging.INFO)
  logger = logging.getLogger(__name__)

  # Configuration
  OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY", "your-openrouter-api-key-here")
  MODEL_NAME = "mistralai/mistral-7b-instruct"

  @dataclass
  class LegalDocument:
      """Legal document structure"""
      title: str
      content: str
      date: str
      court: str
      case_number: str
      summary: str
      embedding: np.ndarray = None

  @dataclass
  class LegalQuery:
      """Legal query structure"""
      question: str
      context: str
      year: int
      legal_area: str

  class WebScraper:
      """Web scraper for legal documents and precedents"""

      def __init__(self):
          self.session = requests.Session()
          self.session.headers.update({
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
          })

      def scrape_legal_precedents(self) -> List[Dict[str, str]]:
          """Scrape legal precedents and landmark judgments"""
          # Simulated legal documents (in real implementation, scrape from legal databases)
          legal_docs = [
              {
                  "title": "Justice K.S. Puttaswamy (Retd.) and Another vs Union of India",
                  "content": """The Supreme Court of India in 2017 unanimously declared that the Right to Privacy is a fundamental right under Article 21 of the Constitution. The nine-judge bench held that privacy is intrinsic to life and liberty and is inherent in the very concept of ordered liberty. The judgment stated that informational privacy, which stems from the right to privacy, includes the right of individuals to exercise control over their personal data and to be able to correct and amend such data. The Court recognized that in the digital age, privacy concerns have acquired new dimensions and the protection of personal data has become crucial.""",
                  "date": "2017-08-24",
                  "court": "Supreme Court of India",
                  "case_number": "WP(C) No 494 of 2012",
                  "summary": "Landmark judgment establishing Right to Privacy as fundamental right under Article 21"
              },
              {
                  "title": "Aadhaar (Targeted Delivery of Financial and Other Subsidies) Act, 2016 - Constitutional Validity",
                  "content": """The Supreme Court in 2018 upheld the constitutional validity of Aadhaar but with significant restrictions. The Court held that while Aadhaar can be mandatory for PAN, filing of income tax returns, and welfare schemes funded by the Consolidated Fund of India, it cannot be made mandatory for bank accounts, mobile phone connections, school admissions, or other services. The judgment emphasized that any authentication mechanism should be proportionate and should not violate the right to privacy.""",
                  "date": "2018-09-26",
                  "court": "Supreme Court of India",
                  "case_number": "WP(C) No 494 of 2012",
                  "summary": "Supreme Court restricts mandatory use of Aadhaar while upholding its constitutional validity"
              },
              {
                  "title": "Shreya Singhal vs Union of India",
                  "content": """The Supreme Court struck down Section 66A of the Information Technology Act, 2000, which criminalized online speech. The Court held that the section was unconstitutional as it violated the fundamental right to freedom of speech and expression. The judgment emphasized the importance of balancing free speech with reasonable restrictions and the need for clear legal provisions that do not create chilling effects on legitimate expression.""",
                  "date": "2015-03-24",
                  "court": "Supreme Court of India",
                  "case_number": "WP(C) No 167 of 2012",
                  "summary": "Section 66A of IT Act struck down for violating freedom of speech"
              },
              {
                  "title": "State of Gujarat vs Mirzapur Moti Kureshi Kassab Jamat",
                  "content": """The Supreme Court emphasized that any governmental action that interferes with fundamental rights must satisfy the test of proportionality. The action must be suitable for achieving the legitimate aim, necessary (no less intrusive means available), and proportionate in the narrow sense (not imposing excessive burden). This principle is crucial in cases involving privacy rights and government policies.""",
                  "date": "2005-10-28",
                  "court": "Supreme Court of India",
                  "case_number": "Civil Appeal No 1051 of 2005",
                  "summary": "Established proportionality test for governmental actions affecting fundamental rights"
              },
              {
                  "title": "X vs. Google India - Right to be Forgotten (Delhi HC 2017)",
          "content": """Delhi High Court in 2017 considered a petition for removal of personal information from search results. The court balanced the right to privacy against freedom of information, noting that outdated criminal records can cause disproportionate harm to rehabilitation efforts.""",
          "date": "2017-12-15",
          "court": "Delhi High Court",
          "case_number": "WP(C) 12/2017",
          "summary": "First Indian case addressing right to be forgotten principles"
      },
      {
          "title": "Subramanian Swamy vs. Union of India - Criminal Record Disclosure",
          "content": """Supreme Court addressed the balance between transparency in criminal justice and individual privacy rights. The court noted that rehabilitation is a constitutional goal and indefinite punishment through public shaming violates human dignity.""",
          "date": "2019-03-22",
          "court": "Supreme Court of India",
          "case_number": "WP(C) 44/2019",
          "summary": "Balanced criminal record disclosure with rehabilitation rights"
      }

          ]

          logger.info(f"Retrieved {len(legal_docs)} legal documents")
          return legal_docs

  class VectorDatabase:
      """Vector database for storing and retrieving legal documents"""

      def __init__(self, embedding_model_name: str = "all-MiniLM-L6-v2"):
          self.embedding_model = SentenceTransformer(embedding_model_name)
          self.documents = []
          self.index = None
          self.dimension = 384  # Dimension for all-MiniLM-L6-v2

      def add_documents(self, legal_docs: List[Dict[str, str]]):
          """Add legal documents to the vector database"""
          for doc in legal_docs:
              # Create embedding for the content
              content = f"{doc['title']} {doc['content']} {doc['summary']}"
              embedding = self.embedding_model.encode(content)

              legal_doc = LegalDocument(
                  title=doc['title'],
                  content=doc['content'],
                  date=doc['date'],
                  court=doc['court'],
                  case_number=doc['case_number'],
                  summary=doc['summary'],
                  embedding=embedding
              )
              self.documents.append(legal_doc)

          # Build FAISS index
          embeddings = np.array([doc.embedding for doc in self.documents])
          self.index = faiss.IndexFlatIP(self.dimension)
          self.index.add(embeddings.astype('float32'))

          logger.info(f"Added {len(self.documents)} documents to vector database")

      def search(self, query: str, k: int = 3) -> List[Tuple[LegalDocument, float]]:
          """Search for relevant legal documents"""
          if self.index is None:
              return []

          query_embedding = self.embedding_model.encode(query).reshape(1, -1)
          scores, indices = self.index.search(query_embedding.astype('float32'), k)

          results = []
          for score, idx in zip(scores[0], indices[0]):
              if idx < len(self.documents):
                  results.append((self.documents[idx], float(score)))

          return results

  class LLMClient:
      """Client for OpenRouter LLM API"""

      def __init__(self, api_key: str, model: str):
          self.client = OpenAI(
              base_url="https://openrouter.ai/api/v1",
              api_key=api_key,
          )
          self.model = model

      async def generate_response(self, messages: List[Dict[str, str]], max_tokens: int = 1000) -> str:
          """Generate response using LLM"""
          try:
              response = self.client.chat.completions.create(
                  model=self.model,
                  messages=messages,
                  max_tokens=max_tokens,
                  temperature=0.7
              )
              return response.choices[0].message.content
          except Exception as e:
              logger.error(f"Error generating LLM response: {e}")
              return f"Error: {str(e)}"

  class LegalReasoningAgent:
      """Agent responsible for legal reasoning and analysis"""

      def __init__(self, llm_client: LLMClient):
          self.llm_client = llm_client

      async def analyze_precedents(self, precedents: List[Tuple[LegalDocument, float]], query: str) -> Dict[str, Any]:
          """Analyze relevant precedents for the given query"""
          precedent_text = ""
          for doc, score in precedents:
              precedent_text += f"\n\nCase: {doc.title}\nDate: {doc.date}\nCourt: {doc.court}\nSummary: {doc.summary}\nContent: {doc.content[:500]}...\n"

          prompt = f"""
          As a legal expert, analyze the following precedents in relation to the query: {query}

          Precedents:
          {precedent_text}

          Provide analysis on:
          1. Relevance of each precedent to the current case
          2. Key legal principles established
          3. How these precedents might apply to the current situation
          4. Any distinguishing factors

          Format your response as a structured analysis.
          """

          messages = [{"role": "user", "content": prompt}]
          response = await self.llm_client.generate_response(messages, max_tokens=800)

          return {
              "analysis": response,
              "precedents_used": len(precedents),
              "confidence": min(sum([score for _, score in precedents]) / len(precedents), 1.0)
          }

      async def generate_arguments(self, case_details: str, precedent_analysis: str, side: str) -> str:
          """Generate legal arguments for a specific side"""
          prompt = f"""
          As a legal expert representing the {side}, craft compelling legal arguments based on:

          Case Details: {case_details}

          Precedent Analysis: {precedent_analysis}

          Generate strong legal arguments that:
          1. Reference relevant precedents appropriately
          2. Apply legal principles correctly
          3. Address potential counterarguments
          4. Follow proper legal reasoning structure
          5. Cite constitutional provisions where relevant

          Present your arguments in a structured legal brief format.
          """

          messages = [{"role": "user", "content": prompt}]
          return await self.llm_client.generate_response(messages, max_tokens=1200)

  class VerdictPredictionAgent:
      """Agent for predicting likely legal outcomes"""

      def __init__(self, llm_client: LLMClient):
          self.llm_client = llm_client

      async def predict_outcome(self, case_details: str, precedent_analysis: str, arguments: Dict[str, str]) -> Dict[str, Any]:
          """Predict likely verdict and reasoning"""
          prompt = f"""
          As a senior legal analyst, predict the likely outcome of this case:

          Case Details: {case_details}

          Precedent Analysis: {precedent_analysis}

          Petitioner Arguments: {arguments.get('petitioner', 'N/A')}

          Respondent Arguments: {arguments.get('respondent', 'N/A')}

          Provide:
          1. Most likely verdict (with confidence percentage)
          2. Key reasoning factors
          3. Potential areas of judicial concern
          4. Alternative outcomes and their likelihood
          5. Timeline estimation for resolution

          Base your prediction on legal precedents, constitutional principles, and judicial trends.
          """

          messages = [{"role": "user", "content": prompt}]
          response = await self.llm_client.generate_response(messages, max_tokens=1000)

          # Extract confidence score (simplified)
          confidence_match = re.search(r'(\d+)%', response)
          confidence = int(confidence_match.group(1)) if confidence_match else 70

          return {
              "prediction": response,
              "confidence": confidence / 100,
              "timestamp": datetime.now().isoformat()
          }

  class LegalIntelligenceSystem:
      """Main orchestrator for the Legal Intelligence System"""

      def __init__(self, api_key: str):
          self.scraper = WebScraper()
          self.vector_db = VectorDatabase()
          self.llm_client = LLMClient(api_key, MODEL_NAME)
          self.reasoning_agent = LegalReasoningAgent(self.llm_client)
          self.verdict_agent = VerdictPredictionAgent(self.llm_client)
          self.initialized = False

      async def initialize(self):
          """Initialize the system with legal documents"""
          if self.initialized:
              return

          logger.info("Initializing Legal Intelligence System...")

          # Scrape and index legal documents
          legal_docs = self.scraper.scrape_legal_precedents()
          self.vector_db.add_documents(legal_docs)

          self.initialized = True
          logger.info("System initialization complete")

      async def process_legal_query(self, query: str, case_details: str = None) -> Dict[str, Any]:
          """Process a complete legal query with multi-agent workflow"""
          if not self.initialized:
              await self.initialize()

          logger.info(f"Processing legal query: {query[:100]}...")

          # Step 1: Retrieve relevant precedents
          precedents = self.vector_db.search(query, k=3)

          if not precedents:
              return {"error": "No relevant precedents found"}

          # Step 2: Analyze precedents
          precedent_analysis = await self.reasoning_agent.analyze_precedents(precedents, query)

          # Step 3: Generate arguments for both sides
          full_case = f"{query}\n\nAdditional Context: {case_details or 'Standard case analysis requested'}"

          petitioner_args = await self.reasoning_agent.generate_arguments(
              full_case, precedent_analysis['analysis'], "petitioner"
          )

          respondent_args = await self.reasoning_agent.generate_arguments(
              full_case, precedent_analysis['analysis'], "respondent (government/state)"
          )

          arguments = {
              "petitioner": petitioner_args,
              "respondent": respondent_args
          }

          # Step 4: Predict verdict
          verdict_prediction = await self.verdict_agent.predict_outcome(
              full_case, precedent_analysis['analysis'], arguments
          )

          return {
              "query": query,
              "precedents": [{"title": doc.title, "date": doc.date, "relevance_score": score}
                            for doc, score in precedents],
              "precedent_analysis": precedent_analysis,
              "arguments": arguments,
              "verdict_prediction": verdict_prediction,
              "processing_timestamp": datetime.now().isoformat()
          }

  # Global system instance
  legal_system = LegalIntelligenceSystem(OPENROUTER_API_KEY)

  async def process_case_async(query, case_details):
      """Async wrapper for case processing"""
      try:
          result = await legal_system.process_legal_query(query, case_details)
          return result
      except Exception as e:
          logger.error(f"Error processing case: {e}")
          return {"error": f"Processing error: {str(e)}"}

  def process_case_sync(query, case_details):
      """Synchronous wrapper for Gradio"""
      loop = asyncio.new_event_loop()
      asyncio.set_event_loop(loop)
      try:
          result = loop.run_until_complete(process_case_async(query, case_details))
          return format_results(result)
      finally:
          loop.close()

  def format_results(result):
      """Format results for Gradio display"""
      if "error" in result:
          return f"‚ùå **Error**: {result['error']}", "", "", ""

      # Format precedents
      precedents_text = "## üìö Relevant Precedents\n\n"
      for prec in result['precedents']:
          precedents_text += f"- **{prec['title']}** ({prec['date']}) - Relevance: {prec['relevance_score']:.3f}\n"

      # Format analysis
      analysis_text = f"## üîç Legal Analysis\n\n{result['precedent_analysis']['analysis']}"

      # Format arguments
      arguments_text = f"## ‚öñÔ∏è Legal Arguments\n\n### Petitioner's Arguments\n{result['arguments']['petitioner']}\n\n### Respondent's Arguments\n{result['arguments']['respondent']}"

      # Format prediction
      prediction_text = f"## üéØ Verdict Prediction\n\n{result['verdict_prediction']['prediction']}\n\n**Confidence**: {result['verdict_prediction']['confidence']:.1%}"

      return precedents_text, analysis_text, arguments_text, prediction_text

  def create_gradio_interface():
      """Create Gradio interface for the system"""

      # Sample case for demo
      sample_query = """In 2025, a new case challenges a government policy that mandates all citizens to submit biometric data for accessing public services. A petitioner argues that the policy violates their privacy rights established in the 2017 Supreme Court judgment."""

      sample_context = """The government argues that biometric data collection is necessary for:
  1. Preventing fraud in public service delivery
  2. Ensuring targeted delivery of benefits
  3. National security purposes
  4. Digital India initiative implementation

  The petitioner contends that:
  1. Mandatory biometric collection violates fundamental right to privacy
  2. No opt-out mechanism violates individual autonomy
  3. Data security concerns and potential misuse
  4. Lack of proportionality in the measure"""

      with gr.Blocks(title="Legal Intelligence System - Hannoworks", theme=gr.themes.Soft()) as interface:
          gr.Markdown("""
          # üèõÔ∏è Legal Intelligence Agentic System
          ### Hannoworks Internship Assignment - AI-Powered Legal Analysis

          This system uses advanced AI agents to analyze legal cases, retrieve relevant precedents,
          and provide comprehensive legal reasoning for judiciary-type questions.
          """)

          with gr.Row():
              with gr.Column(scale=1):
                  query_input = gr.Textbox(
                      label="Legal Query",
                      placeholder="Describe the legal case or question...",
                      lines=4,
                      value=sample_query
                  )

                  context_input = gr.Textbox(
                      label="Additional Case Context (Optional)",
                      placeholder="Provide additional context, arguments, or details...",
                      lines=6,
                      value=sample_context
                  )

                  analyze_btn = gr.Button("üîç Analyze Case", variant="primary", size="lg")

          with gr.Row():
              with gr.Column():
                  precedents_output = gr.Markdown(label="Relevant Precedents")
                  analysis_output = gr.Markdown(label="Legal Analysis")

          with gr.Row():
              with gr.Column():
                  arguments_output = gr.Markdown(label="Legal Arguments")
                  prediction_output = gr.Markdown(label="Verdict Prediction")

          # Event handling
          analyze_btn.click(
              fn=process_case_sync,
              inputs=[query_input, context_input],
              outputs=[precedents_output, analysis_output, arguments_output, prediction_output],
              show_progress=True
          )

          # Sample cases
          gr.Markdown("""
          ## üìã Sample Cases to Try:

          1. **Privacy vs Security**: Government mandating biometric data collection
          2. **Freedom of Expression**: Social media content regulation policies
          3. **Digital Rights**: Mandatory digital identity for government services
          4. **Surveillance**: CCTV installation in private residential areas
          """)

      return interface

  # Initialize and launch
  if __name__ == "__main__":
      print("üöÄ Starting Legal Intelligence System...")
      print(f"üìä Model: {MODEL_NAME}")
      print("üîß Initializing components...")

      # Create Gradio interface
      interface = create_gradio_interface()

      # Launch with public sharing for Colab
      interface.launch(
          share=True,  # Creates public link for Colab
          debug=True,
          show_error=True,
          server_name="0.0.0.0",  # Allow external access
          server_port=7860
    )